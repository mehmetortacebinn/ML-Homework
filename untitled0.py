# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cs1M6bjuScU0t8WV5Gf6EnM37XJZFezf
"""

#1.	Ara sınav ödevinde size atanan veri setine tüm algoritmalar için normalizasyon yöntemlerinden birini  uygulayınız.

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import seaborn as sns

#Exploratory Data Analysis
Data = pd.read_csv('/content/veri-seti.txt', delimiter = "\t", header=None)

Data.columns = ["Pregnancies", "Glucose", "BloodPressure", "Skinthickness", "insulin", "Bmi", "Diabetespedigreefunction", "Age", "Outcome"]
Data.head()

Data.shape
Data.dtypes
Data.info()
Data.describe()
Data.isnull().sum()

#5 sütunda 0 değerlerini kontrol ediliyor. Age & DiabetesPedigreeFunction sütunlarında minimum 0 değeri bulunmadığından değiştirmeye gerek yok, ayrıca hamilelik sayısında 0 değeri mümkündür, Data.describe'da gözlemlendiği gibi.
print(Data[Data['BloodPressure']==0].shape[0])
print(Data[Data['Glucose']==0].shape[0])
print(Data[Data['Skinthickness']==0].shape[0])
print(Data[Data['insulin']==0].shape[0])
print(Data[Data['Bmi']==0].shape[0])

#replacing 0 values with median of that column
Data['Glucose']=Data['Glucose'].replace(0,Data['Glucose'].mean())#normal distribution
Data['BloodPressure']=Data['BloodPressure'].replace(0,Data['BloodPressure'].mean())#normal distribution
Data['Skinthickness']=Data['Skinthickness'].replace(0,Data['Skinthickness'].median())#skewed distribution
Data['insulin']=Data['insulin'].replace(0,Data['insulin'].median())#skewed distribution
Data['Bmi']=Data['Bmi'].replace(0,Data['Bmi'].median())#skewed distribution


#Feature Selection
corrmat=Data.corr()
sns.heatmap(corrmat, annot=True)

X = Data[["Pregnancies","Glucose","BloodPressure", "Skinthickness", "insulin", "Bmi", "Diabetespedigreefunction", "Age"]]

Y = Data[["Outcome"]]

X_train,X_test,y_train,y_test = train_test_split(X,Y,train_size=0.7,test_size=0.3,random_state=51)

norm_mmc = MinMaxScaler()

norm_mmc_trans_X_train = norm_mmc.fit_transform(X_train)

norm_mmc_trans_X_test = norm_mmc.fit_transform(X_test)

norm_mmc_trans_X_train_df = pd.DataFrame(norm_mmc_trans_X_train,columns=["Pregnancies","Glucose","BloodPressure", "Skinthickness", "insulin", "Bmi", "Diabetespedigreefunction", "Age"])

norm_mmc_trans_X_train_df.head()

norm_mmc_trans_X_test_df = pd.DataFrame(norm_mmc_trans_X_test,columns=["Pregnancies","Glucose","BloodPressure", "Skinthickness", "insulin", "Bmi", "Diabetespedigreefunction", "Age"])

norm_mmc_trans_X_test_df.head()

#2.	Veri setine PCA ve LDA algoritmalarını uygulayarak en yüksek değere sahip iki öz değer için boyut indirgeme işlemini gerçekleştiriniz. PCA ve LDA için hangi özniteliklerin en ayırt edici olduğunu raporlayınız.
#Alt maddelerde verilen yöntemleri ana veri setine ve PCA uygulanmış transformasyon öznitelik matrisine uygulayınız.

from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

# PCA uygula
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

# LDA uygula
lda = LinearDiscriminantAnalysis()
X_lda = lda.fit_transform(X, Y)

# PCA için en ayırt edici öznitelikler
print("PCA için En Ayırt Edici Öznitelikler:")
for i, component in enumerate(pca.components_):
    print(f"Component {i+1}: {', '.join([f'{feat}: {round(value, 4)}' for feat, value in zip(Data.columns, component)])}")

# LDA için en ayırt edici öznitelikler
print("\nLDA için En Ayırt Edici Öznitelikler:")
for i, component in enumerate(lda.scalings_.T):
    print(f"Component {i+1}: {', '.join([f'{feat}: {round(value, 4)}' for feat, value in zip(Data.columns, component)])}")

#3.	Veri setinizi rastgele olarak %70 eğitim %30 test olacak şekilde ayırınız. Eğitim veri seti için Çoklu Doğrusal Regresyon analizi ve Multinominal Lojistik Regresyon analizi yöntemlerini uygulayınız.
#Elde ettiğiniz katsayıları raporlayınız.  Elde ettiğiniz regresyon denklemlerini kullanarak Test kümesi için performans metriklerini hesaplayınız.

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, mean_squared_error
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import precision_score, classification_report

# Veriyi eğitim ve test setlerine ayır
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)

pca = PCA(n_components=2)
X_train = pca.fit_transform(X_train, y_train)
X_test = pca.transform(X_test)


# Çoklu Doğrusal Regresyon modelini eğit
linear_reg = LinearRegression()
linear_reg.fit(X_train, Y_train)

# Multinominal Lojistik Regresyon modelini eğit
logistic_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs')
log = logistic_reg.fit(X_train, Y_train)

# Katsayıları raporla
print("Çoklu Doğrusal Regresyon Katsayıları:")
print(linear_reg.coef_)
print("\nMultinominal Lojistik Regresyon Katsayıları:")
print(logistic_reg.coef_)

# Çoklu Doğrusal Regresyon denklemi
linear_eq = f"y = {linear_reg.intercept_} "
for i, coef in enumerate(linear_reg.coef_):
    linear_eq += f"+ ({coef} * X{i})"

print("\nÇoklu Doğrusal Regresyon Denklemi:")
print(linear_eq)

# Multinominal Lojistik Regresyon denklemi
logistic_eq = "y = "
for i, coef in enumerate(logistic_reg.coef_[0]):
    logistic_eq += f"({coef} * X{i}) "
print("\nMultinominal Lojistik Regresyon Denklemi:")
print(logistic_eq)

# Test kümesi performans metrikleri
linear_reg_predictions = linear_reg.predict(X_test)
logistic_reg_predictions = logistic_reg.predict(X_test)

linear_reg_mse = mean_squared_error(Y_test, linear_reg_predictions)
logistic_reg_accuracy = accuracy_score(Y_test, logistic_reg_predictions)

print("\nÇoklu Doğrusal Regresyon MSE:", linear_reg_mse)
print("Multinominal Lojistik Regresyon Doğruluğu:", logistic_reg_accuracy)

Y_pred = log.predict(X_test)

cm = confusion_matrix(Y_test, Y_pred)

print("Karışıklık Matrisi:")
print(cm)

# Karışıklık matrisini görselleştir
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g',
            xticklabels=['Tahmin 0', 'Tahmin 1'],
            yticklabels=['Gerçek 0', 'Gerçek 1'])
plt.xlabel('Tahmin Edilen')
plt.ylabel('Gerçek Değer')
plt.title('Karışıklık Matrisi')
plt.show()

# Performans metriklerini hesapla
accuracy = accuracy_score(Y_test, Y_pred)
classification_rep = classification_report(Y_test, Y_pred)

print("\nTest Verisi İçin Performans Metrikleri:")
print("Doğruluk:", accuracy)
print("Sınıflandırma Raporu:\n", classification_rep)



"""**YORUM:**
Bu performans metrikleri, çoklu doğrusal regresyon ve multinominal lojistik regresyon analizleri sonucunda elde edilen sonuçların bir özetini sunar. Doğruluk oranı %72,3'tür, yani modelin doğru tahmin etme yeteneği makul bir düzeydedir.

Sınıflandırma raporuna baktığımızda, her sınıf için precision (kesinlik), recall (duyarlılık) ve f1-score (kesinlik ve duyarlılığın harmonik ortalaması) gibi metriklerin hesaplandığını görüyoruz. Sınıf 0 için precision ve recall oranları daha yüksekken, sınıf 1 için daha düşüktür. Bu, modelin sınıf 0'ı daha iyi tahmin ettiğini, ancak sınıf 1'i daha az etkili bir şekilde tahmin ettiğini gösterir.

Ayrıca, weighted average f1-score, modelin sınıf dengesizliğine duyarlılığını ölçer. Bu değer, her sınıfın ağırlıklı ortalamasının f1-score'unu temsil eder. Bu durumda, weighted average f1-score %72'dir.

Bu sonuçlar, modelin makul bir performans sergilediğini, ancak sınıflar arasında dengesizlik olduğunu gösteriyor. Modelin daha iyi bir şekilde ayarlanması veya farklı bir modelin uygulanması, performansı daha da artırabilir.
"""

#4.	Veri setinizi rastgele olarak %70 eğitim %30 test olacak şekilde ayırınız. Veri setinize karar ağaç sınıflandırma algoritmasını uygulayarak ağaç yapısını ve kestirim sonuçlarını veriniz.
#Test verisi için performans metriklerini hesaplayınız.

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.metrics import accuracy_score, classification_report
import graphviz

# Karar ağacı modelini eğit
decision_tree = DecisionTreeClassifier(random_state=42)
decision_tree.fit(X_train, Y_train)

# Ağaç yapısını göster
print("Karar Ağacı Yapısı:")
print(decision_tree.tree_)

# Görselleştirmek aşağıdaki satır kullanılır.
# export_graphviz(decision_tree, out_file="tree.dot", feature_names=X.columns, class_names=["0", "1"], filled=True)

# tree.dot adlı dosyayı görselleştirmek için Graphviz kullanın
with open("tree.dot") as f:
    dot_graph = f.read()
graphviz.Source(dot_graph)

# Test verisi için kestirim sonuçlarını al
Y_pred = decision_tree.predict(X_test)

# Performans metriklerini hesapla
accuracy = accuracy_score(Y_test, Y_pred)
classification_rep = classification_report(Y_test, Y_pred)

print("\nTest Verisi İçin Performans Metrikleri:")
print("Doğruluk:", accuracy)
print("Sınıflandırma Raporu:\n", classification_rep)



"""# YORUM

Verilen performans metriklerine göre, karar ağacı sınıflandırma algoritmasıyla elde edilen sonuçlar değerlendirilmiş. Doğruluk oranı %63,2'dir, yani modelin doğru tahmin etme yeteneği sınırlıdır.

Sınıflandırma raporuna baktığımızda, her sınıf için precision (kesinlik), recall (duyarlılık) ve f1-score (kesinlik ve duyarlılığın harmonik ortalaması) gibi metriklerin hesaplandığını görüyoruz. Sınıf 0 için precision ve recall oranları birbirine yakınken, sınıf 1 için daha düşüktür. Bu, modelin sınıf 0'ı sınıf 1'e göre daha iyi tahmin ettiğini gösterir.

Ayrıca, weighted average f1-score, modelin sınıf dengesizliğine duyarlılığını ölçer. Bu değer, her sınıfın ağırlıklı ortalamasının f1-score'unu temsil eder. Bu durumda, weighted average f1-score %63'tür.

Sonuç olarak, karar ağacı sınıflandırma algoritmasıyla elde edilen sonuçlar, modelin sınırlı bir performans sergilediğini göstermektedir. Modelin daha iyi bir şekilde ayarlanması veya farklı bir modelin uygulanması, performansı daha da artırabilir.
"""

#5.	Veri setinizi rastgele olarak %70 eğitim %30 test olacak şekilde ayırınız. Eğitim veri seti için Naive bayes sınıflandırıcısını uygulayınız.
#Elde ettiğiniz sonucları raporlayınız.  Test verisi için performans metriklerini hesaplayınız.

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report

# Naive Bayes modelini eğit
naive_bayes = GaussianNB()
naive_bayes.fit(X_train, Y_train)

# Eğitim veri seti için sonuçları raporla
train_predictions = naive_bayes.predict(X_train)
train_accuracy = accuracy_score(Y_train, train_predictions)
train_classification_report = classification_report(Y_train, train_predictions)

print("Eğitim Verisi İçin Sonuçlar:")
print("Doğruluk:", train_accuracy)
print("Sınıflandırma Raporu:\n", train_classification_report)

# Test verisi için performans metriklerini hesapla
test_predictions = naive_bayes.predict(X_test)
test_accuracy = accuracy_score(Y_test, test_predictions)
test_classification_report = classification_report(Y_test, test_predictions)

print("\nTest Verisi İçin Performans Metrikleri:")
print("Doğruluk:", test_accuracy)
print("Sınıflandırma Raporu:\n", test_classification_report)

"""# YORUM
Naive Bayes sınıflandırıcısıyla elde edilen sonuçlar oldukça önemlidir. Öncelikle, eğitim verisi için elde edilen sonuçlara bakalım:

Eğitim Verisi İçin Sonuçlar:

Doğruluk: %74,49
Sınıflandırma Raporu:
Sınıf 0 için precision: %76, recall: %89, f1-score: %82
Sınıf 1 için precision: %69, recall: %48, f1-score: %57
Ağırlıklı (weighted) ortalama f1-score: %73
Test Verisi İçin Sonuçlar:

Doğruluk: %73,59
Sınıflandırma Raporu:
Sınıf 0 için precision: %77, recall: %85, f1-score: %81
Sınıf 1 için precision: %65, recall: %51, f1-score: %57
Ağırlıklı (weighted) ortalama f1-score: %73
Her iki veri seti için de, sınıf 0'ın sınıf 1'e göre daha iyi tahmin edildiği görülüyor. Ancak, sınıf dengesizliğinden kaynaklanan bir eğilim olduğu da gözlemlenebilir.

Naive Bayes sınıflandırıcısı, basit ancak etkili bir sınıflandırma algoritmasıdır. Ancak, veri setinizin özelliklerine ve sınıf dengesizliğine bağlı olarak, daha karmaşık modellerin veya farklı sınıflandırıcıların da performansını karşılaştırmak önemli olabilir. Ayrıca, modelinizin hiperparametrelerini ayarlamanın veya özellik mühendisliği yapmanın performansı artırabileceğini de göz önünde bulundurmalısınız.

# ***PCA LDA uygulanmamış versiyon aşağıdadır!***
"""

#1.	Ara sınav ödevinde size atanan veri setine tüm algoritmalar için normalizasyon yöntemlerinden birini  uygulayınız.

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler


#Exploratory Data Analysis
Data = pd.read_csv('/content/veri-seti.txt', delimiter = "\t", header=None)

Data.columns = ["Pregnancies", "Glucose", "BloodPressure", "Skinthickness", "insulin", "Bmi", "Diabetespedigreefunction", "Age", "Outcome"]
Data.head()

Data.shape
Data.dtypes
Data.info()
Data.describe()
Data.isnull().sum()

#5 sütunda 0 değerlerini kontrol ediliyor. Age & DiabetesPedigreeFunction sütunlarında minimum 0 değeri bulunmadığından değiştirmeye gerek yok, ayrıca hamilelik sayısında 0 değeri mümkündür, Data.describe'da gözlemlendiği gibi.
print(Data[Data['BloodPressure']==0].shape[0])
print(Data[Data['Glucose']==0].shape[0])
print(Data[Data['Skinthickness']==0].shape[0])
print(Data[Data['insulin']==0].shape[0])
print(Data[Data['Bmi']==0].shape[0])

#replacing 0 values with median of that column
Data['Glucose']=Data['Glucose'].replace(0,Data['Glucose'].mean())#normal distribution
Data['BloodPressure']=Data['BloodPressure'].replace(0,Data['BloodPressure'].mean())#normal distribution
Data['Skinthickness']=Data['Skinthickness'].replace(0,Data['Skinthickness'].median())#skewed distribution
Data['insulin']=Data['insulin'].replace(0,Data['insulin'].median())#skewed distribution
Data['Bmi']=Data['Bmi'].replace(0,Data['Bmi'].median())#skewed distribution


#Feature Selection
corrmat=Data.corr()
sns.heatmap(corrmat, annot=True)

X = Data[["Pregnancies","Glucose","BloodPressure", "Skinthickness", "insulin", "Bmi", "Diabetespedigreefunction", "Age"]]

Y = Data[["Outcome"]]

X_train,X_test,y_train,y_test = train_test_split(X,Y,train_size=0.7,test_size=0.3,random_state=51)

norm_mmc = MinMaxScaler()

norm_mmc_trans_X_train = norm_mmc.fit_transform(X_train)

norm_mmc_trans_X_test = norm_mmc.fit_transform(X_test)

norm_mmc_trans_X_train_df = pd.DataFrame(norm_mmc_trans_X_train,columns=["Pregnancies","Glucose","BloodPressure", "Skinthickness", "insulin", "Bmi", "Diabetespedigreefunction", "Age"])

norm_mmc_trans_X_train_df.head()

norm_mmc_trans_X_test_df = pd.DataFrame(norm_mmc_trans_X_test,columns=["Pregnancies","Glucose","BloodPressure", "Skinthickness", "insulin", "Bmi", "Diabetespedigreefunction", "Age"])

norm_mmc_trans_X_test_df.head()

#3.	Veri setinizi rastgele olarak %70 eğitim %30 test olacak şekilde ayırınız. Eğitim veri seti için Çoklu Doğrusal Regresyon analizi ve Multinominal Lojistik Regresyon analizi yöntemlerini uygulayınız.
#Elde ettiğiniz katsayıları raporlayınız.  Elde ettiğiniz regresyon denklemlerini kullanarak Test kümesi için performans metriklerini hesaplayınız.

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, mean_squared_error
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import precision_score


# Veriyi eğitim ve test setlerine ayır
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)

# Çoklu Doğrusal Regresyon modelini eğit
linear_reg = LinearRegression()
linear_reg.fit(X_train, Y_train)

# Multinominal Lojistik Regresyon modelini eğit
logistic_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs')
log = logistic_reg.fit(X_train, Y_train)

# Katsayıları raporla
print("Çoklu Doğrusal Regresyon Katsayıları:")
print(linear_reg.coef_)
print("\nMultinominal Lojistik Regresyon Katsayıları:")
print(logistic_reg.coef_)

# Çoklu Doğrusal Regresyon denklemi
linear_eq = f"y = {linear_reg.intercept_} "
for i, coef in enumerate(linear_reg.coef_):
    linear_eq += f"+ ({coef} * X{i})"

print("\nÇoklu Doğrusal Regresyon Denklemi:")
print(linear_eq)

# Multinominal Lojistik Regresyon denklemi
logistic_eq = "y = "
for i, coef in enumerate(logistic_reg.coef_[0]):
    logistic_eq += f"({coef} * X{i}) "
print("\nMultinominal Lojistik Regresyon Denklemi:")
print(logistic_eq)

# Test kümesi performans metrikleri
linear_reg_predictions = linear_reg.predict(X_test)
logistic_reg_predictions = logistic_reg.predict(X_test)

linear_reg_mse = mean_squared_error(Y_test, linear_reg_predictions)
logistic_reg_accuracy = accuracy_score(Y_test, logistic_reg_predictions)

print("\nÇoklu Doğrusal Regresyon MSE:", linear_reg_mse)
print("Multinominal Lojistik Regresyon Doğruluğu:", logistic_reg_accuracy)

Y_pred = log.predict(X_test)

cm = confusion_matrix(Y_test, Y_pred)

print("Karışıklık Matrisi:")
print(cm)

# Karışıklık matrisini görselleştir
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g',
            xticklabels=['Tahmin 0', 'Tahmin 1'],
            yticklabels=['Gerçek 0', 'Gerçek 1'])
plt.xlabel('Tahmin Edilen')
plt.ylabel('Gerçek Değer')
plt.title('Karışıklık Matrisi')
plt.show()

# Performans metriklerini hesapla
accuracy = accuracy_score(Y_test, Y_pred)
classification_rep = classification_report(Y_test, Y_pred)

print("\nTest Verisi İçin Performans Metrikleri:")
print("Doğruluk:", accuracy)
print("Sınıflandırma Raporu:\n", classification_rep)

"""# YORUM
Bu performans metrikleri, çoklu doğrusal regresyon ve multinominal lojistik regresyon analizleri sonucunda elde edilen sonuçların bir özetini sunar. Doğruluk oranı %75,3'tür, yani modelin doğru tahmin etme yeteneği makul bir düzeydedir.

Sınıflandırma raporuna baktığımızda, her sınıf için precision (kesinlik), recall (duyarlılık) ve f1-score (kesinlik ve duyarlılığın harmonik ortalaması) gibi metriklerin hesaplandığını görüyoruz. Sınıf 0 için precision ve recall oranları birbirine yakınken, sınıf 1 için daha düşüktür. Bu, modelin sınıf 0'ı sınıf 1'e göre daha iyi tahmin ettiğini gösterir. Ayrıca, weighted average f1-score, modelin sınıf dengesizliğine duyarlılığını ölçer. Bu değer, her sınıfın ağırlıklı ortalamasının f1-score'unu temsil eder. Bu durumda, weighted average f1-score %75'tir.

Bu sonuçlar, modelin makul bir performans sergilediğini, ancak sınıflar arasında dengesizlik olduğunu göstermektedir. Modelin daha iyi bir şekilde ayarlanması veya farklı bir modelin uygulanması, performansı daha da artırabilir.

"""

#4.	Veri setinizi rastgele olarak %70 eğitim %30 test olacak şekilde ayırınız. Veri setinize karar ağaç sınıflandırma algoritmasını uygulayarak ağaç yapısını ve kestirim sonuçlarını veriniz.
#Test verisi için performans metriklerini hesaplayınız.

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.metrics import accuracy_score, classification_report
import graphviz

# Karar ağacı modelini eğit
decision_tree = DecisionTreeClassifier(random_state=42)
decision_tree.fit(X_train, Y_train)

# Ağaç yapısını göster
print("Karar Ağacı Yapısı:")
print(decision_tree.tree_)

#export_graphviz(decision_tree, out_file="tree.dot", feature_names=X.columns, class_names=["0", "1"], filled=True)

# tree.dot adlı dosyayı görselleştirmek için Graphviz kullanın
with open("tree.dot") as f:
    dot_graph = f.read()
graphviz.Source(dot_graph)

# Test verisi için kestirim sonuçlarını al
Y_pred = decision_tree.predict(X_test)

# Performans metriklerini hesapla
accuracy = accuracy_score(Y_test, Y_pred)
classification_rep = classification_report(Y_test, Y_pred)

print("\nTest Verisi İçin Performans Metrikleri:")
print("Doğruluk:", accuracy)
print("Sınıflandırma Raporu:\n", classification_rep)

"""# YORUM
Modelin doğruluk oranı %71,43'tür, yani test verisi üzerinde doğru tahmin etme yeteneği orta düzeydedir.

Sınıflandırma raporu incelendiğinde, sınıf 0'ın sınıf 1'e göre daha iyi tahmin edildiği görülüyor. Ancak, sınıf 1 için recall oranı sınıf 0'a göre daha yüksektir, bu da sınıf 1'ın doğru tahmin edilmesinde daha başarılı olduğunu gösterir.

Modelin performansını iyileştirmek için, ağaç yapısının daha derinlemesine incelenmesi veya modelin hiperparametrelerinin ayarlanması gibi adımlar atılabilir.
"""

#5.	Veri setinizi rastgele olarak %70 eğitim %30 test olacak şekilde ayırınız. Eğitim veri seti için Naive bayes sınıflandırıcısını uygulayınız.
#Elde ettiğiniz sonucları raporlayınız.  Test verisi için performans metriklerini hesaplayınız.

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report


# Naive Bayes modelini eğit
naive_bayes = GaussianNB()
naive_bayes.fit(X_train, Y_train)

# Eğitim veri seti için sonuçları raporla
train_predictions = naive_bayes.predict(X_train)
train_accuracy = accuracy_score(Y_train, train_predictions)
train_classification_report = classification_report(Y_train, train_predictions)

print("Eğitim Verisi İçin Sonuçlar:")
print("Doğruluk:", train_accuracy)
print("Sınıflandırma Raporu:\n", train_classification_report)

# Test verisi için performans metriklerini hesapla
test_predictions = naive_bayes.predict(X_test)
test_accuracy = accuracy_score(Y_test, test_predictions)
test_classification_report = classification_report(Y_test, test_predictions)

print("\nTest Verisi İçin Performans Metrikleri:")
print("Doğruluk:", test_accuracy)
print("Sınıflandırma Raporu:\n", test_classification_report)

"""# YORUM
Eğitim ve test veri setleri için de, sınıf 0'ın sınıf 1'e göre daha iyi tahmin edildiği görülüyor.

Modelin performansı eğitim ve test veri setleri arasında benzerdir, bu da modelin genelleme yeteneğinin iyi olduğunu gösterebilir.
Ancak, sınıf 1'in recall (duyarlılık) değeri, sınıf 0'a göre biraz daha düşüktür. Bu, modelin sınıf 1'ı tahmin etme konusunda daha zayıf olduğunu gösterebilir.

Naive Bayes sınıflandırıcısı, basit ancak etkili bir sınıflandırma algoritmasıdır. Ancak, veri setinizin özelliklerine ve sınıf dengesizliğine bağlı olarak, daha karmaşık modellerin veya farklı sınıflandırıcıların da performansını karşılaştırmak önemli olabilir.

"""